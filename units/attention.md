# Attention, Transformer, BERT

## Slides

* Attention, Transformer, BERT
  [Keynote](../../slides/4_25/24-Attention.key),
  [PDF](../../slides/4_25/24-Attention.pdf)

* Notebooks
  - Attention Layer [Jupyter](../../slides/4_25/attention.ipynb),
    [HTML](https://nbviewer.jupyter.org/url/courses.d2l.ai/berkeley-stat-157/slides/4_25/attention.ipynb)
  - Seq2seq with Attention [Jupyter](../../slides/4_25/seq2seq-attention.ipynb),
    [HTML](https://nbviewer.jupyter.org/url/courses.d2l.ai/berkeley-stat-157/slides/4_25/seq2seq-attention.ipynb)
  - Transformer [Jupyter](../../slides/4_25/transformer.ipynb),
    [HTML](https://nbviewer.jupyter.org/url/courses.d2l.ai/berkeley-stat-157/slides/4_25/transformer.ipynb)
